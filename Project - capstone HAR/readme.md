1. **Project Overview**

    The availability of affordable wearable equipments and portable computing devices results in behemoth amount of data being collected including motion, location, physiological signals and environmental information. The human activity recognition (HAR) is an active research field to understand how human behaviours are developed by interpreting attributes derived from this data. Accurately solving HAR problems can provide direct assistance in many fields including healthcare, transportation and virtual reality. 

    With the availability of data, analyses can be done to better recognise, classify, cluster and predict what human activities are carried out (e.g. stand, sit, lie, walk) for further decision making. Several papers already exploited this area, using supervised and semi-supervised learning methods such as support vector machine, ensemble methods with boosting and, deep learning techniques such as artificial neural network. 

2. **Packages Used**

    The following packages are required to execute the code in the jupyter notebook. 

    * numpy
    * pandas
    * matplotlib
    * scikit-learn
    * keras

3. **Data** 

    The dataset used was an archived dataset titled *Smartphone-Based Recognition of Human Activities and Postural Transitions Data Set* from University of California, Irving.  It was built from the recordings of 30 subjects performing basic activities and postural transitions while carrying a waist-mounted smartphone with embedded inertial sensors. Detailed description of the data set can be found [here](http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions#). 

4. **Results**

    The project notebook can be found in this repo and you can read the blog [here](https://medium.com/@xiaoshansun/human-activity-recognition-using-smartphones-sensor-data-fd1af142cc81). 
